#!/usr/bin/env python3
"""
Test script for core Databricks DDL Generator improvements.
Tests the core functions without importing streamlit.
"""

import json
import re
from typing import Dict, List, Any, Optional, Tuple

# Copy the core functions and constants from app.py to test them independently

# Enhanced data type mapping configuration
DATABRICKS_TYPE_MAPPING = {
    # Common mappings
    'VARCHAR': 'STRING',
    'VARCHAR(255)': 'STRING',
    'CHAR': 'STRING',
    'TEXT': 'STRING',
    'NVARCHAR': 'STRING',
    'NCHAR': 'STRING',
    'CLOB': 'STRING',
    
    # Numeric types
    'INTEGER': 'INT',
    'INT': 'INT',
    'SMALLINT': 'SMALLINT',
    'TINYINT': 'TINYINT',
    'BIGINT': 'BIGINT',
    'FLOAT': 'DOUBLE',
    'REAL': 'FLOAT',
    'DOUBLE': 'DOUBLE',
    'DOUBLE PRECISION': 'DOUBLE',
    'DECIMAL': 'DECIMAL',
    'NUMERIC': 'DECIMAL',
    'NUMBER': 'DECIMAL',
    'MONEY': 'DECIMAL(19,4)',
    'SMALLMONEY': 'DECIMAL(10,4)',
    
    # Boolean and bit types
    'BOOLEAN': 'BOOLEAN',
    'BOOL': 'BOOLEAN',
    'BIT': 'BOOLEAN',  # Key mapping from feedback
    
    # Date and time types
    'DATE': 'DATE',
    'TIME': 'STRING',  # Databricks doesn't have TIME type
    'DATETIME': 'TIMESTAMP',
    'DATETIME2': 'TIMESTAMP',
    'SMALLDATETIME': 'TIMESTAMP',
    'TIMESTAMP': 'TIMESTAMP',
    'TIMESTAMP_TZ': 'TIMESTAMP',
    'TIMESTAMPTZ': 'TIMESTAMP',
    
    # Binary types
    'BINARY': 'BINARY',
    'VARBINARY': 'BINARY',
    'BLOB': 'BINARY',
    'IMAGE': 'BINARY',
    
    # Other types
    'UUID': 'STRING',
    'UNIQUEIDENTIFIER': 'STRING',
    'XML': 'STRING',
    'JSON': 'STRING',
    'JSONB': 'STRING',
}

# Supported Databricks attribute parameters for identity and other features
SUPPORTED_DATABRICKS_ATTRIBUTES = {
    'identity': 'GENERATED BY DEFAULT AS IDENTITY',
    'generated_always': 'GENERATED ALWAYS AS IDENTITY',
    'auto_increment': 'GENERATED BY DEFAULT AS IDENTITY',
    'serial': 'GENERATED BY DEFAULT AS IDENTITY',
}

def map_datatype_to_databricks(data_type: str, handle_incompatible: bool = True) -> str:
    """
    Map the data type from the model to Databricks supported types.
    
    Parameters:
        data_type: The original data type
        handle_incompatible: Whether to map incompatible types to compatible ones
    
    Returns:
        Databricks-compatible data type
    """
    if not handle_incompatible:
        return data_type
    
    # Normalize the data type
    data_type_upper = data_type.upper().strip()
    
    # Handle VARCHAR/CHAR with length specification
    if re.match(r'VARCHAR\(\d+\)', data_type_upper) or re.match(r'CHAR\(\d+\)', data_type_upper):
        return 'STRING'
    
    # Handle DECIMAL/NUMERIC with precision and scale
    decimal_match = re.match(r'(DECIMAL|NUMERIC)\((\d+),(\d+)\)', data_type_upper)
    if decimal_match:
        precision, scale = decimal_match.groups()[1], decimal_match.groups()[2]
        return f'DECIMAL({precision},{scale})'
    
    # Handle DECIMAL/NUMERIC with precision only
    decimal_match = re.match(r'(DECIMAL|NUMERIC)\((\d+)\)', data_type_upper)
    if decimal_match:
        precision = decimal_match.groups()[1]
        return f'DECIMAL({precision},0)'
    
    # Try exact match first
    if data_type_upper in DATABRICKS_TYPE_MAPPING:
        return DATABRICKS_TYPE_MAPPING[data_type_upper]
    
    # If no mapping found, return original type
    return data_type

def get_identity_clause(metadata: Dict[str, Any]) -> str:
    """
    Generate identity clause based on attribute metadata.
    
    Parameters:
        metadata: Attribute metadata dictionary
    
    Returns:
        Identity clause string or empty string
    """
    # Check for various identity indicators in metadata
    for key, clause in SUPPORTED_DATABRICKS_ATTRIBUTES.items():
        if metadata.get(key, False) or metadata.get(key.upper(), False):
            return clause
    
    # Check for identity in description or other fields
    description = metadata.get('description', '').lower()
    if 'identity' in description or 'auto increment' in description or 'serial' in description:
        return SUPPORTED_DATABRICKS_ATTRIBUTES['identity']
    
    return ""

def format_column_definition(col_name: str, data_type: str, not_null: bool = False, 
                           comment: str = "", identity_clause: str = "", 
                           max_name_width: int = 20, max_type_width: int = 15) -> str:
    """
    Format a column definition with proper alignment for readability.
    
    Parameters:
        col_name: Column name
        data_type: Data type
        not_null: Whether column is NOT NULL
        comment: Column comment
        identity_clause: Identity clause (e.g., GENERATED BY DEFAULT AS IDENTITY)
        max_name_width: Maximum width for column name padding
        max_type_width: Maximum width for data type padding
    
    Returns:
        Formatted column definition
    """
    # Pad column name and data type for alignment
    padded_name = col_name.ljust(max_name_width)
    padded_type = data_type.ljust(max_type_width)
    
    column_def = f"  {padded_name} {padded_type}"
    
    # Add identity clause if present
    if identity_clause:
        column_def += f" {identity_clause}"
    
    # Add NOT NULL constraint
    if not_null:
        column_def += " NOT NULL"
    
    # Add comment if available
    if comment:
        # Escape single quotes in comment
        escaped_comment = comment.replace("'", "''")
        column_def += f" COMMENT '{escaped_comment}'"
    
    return column_def

def sanitize_identifier(name: str, sanitize_method: str = "underscore") -> str:
    """
    Sanitize SQL identifiers (table names, column names) to handle spaces and special characters.
    
    Parameters:
        name: The identifier to sanitize
        sanitize_method: Method to use for sanitization:
            - "underscore": Replace spaces and special chars with underscores (Databricks-compatible)
            - "backtick": Quote with backticks (may cause issues with Databricks)
    
    Returns:
        Sanitized identifier
    """
    if not name:
        return name
    
    # Remove any existing quotes if they exist
    name = name.strip('`"')
    
    if sanitize_method == "underscore":
        # Replace spaces and special characters with underscore
        # Keep alphanumeric and underscore characters
        return re.sub(r'[^a-zA-Z0-9_]', '_', name)
    else:  # backtick
        return f"`{name}`"

def test_data_type_mapping():
    """Test F-1: Data type mapping engine"""
    print("üß™ Testing Data Type Mapping...")
    
    # Test cases for data type mapping
    test_cases = [
        # Key mapping from feedback - BIT should map to BOOLEAN
        ("BIT", True, "BOOLEAN"),
        ("BIT", False, "BIT"),
        
        # Other important mappings
        ("VARCHAR(255)", True, "STRING"),
        ("INTEGER", True, "INT"),
        ("FLOAT", True, "DOUBLE"),
        ("DATETIME", True, "TIMESTAMP"),
        ("MONEY", True, "DECIMAL(19,4)"),
        ("DECIMAL(10,2)", True, "DECIMAL(10,2)"),
        ("NUMERIC(8)", True, "DECIMAL(8,0)"),
        
        # Non-existent type should return original when not handling
        ("CUSTOM_TYPE", False, "CUSTOM_TYPE"),
        ("CUSTOM_TYPE", True, "CUSTOM_TYPE"),  # No mapping exists
    ]
    
    all_passed = True
    for original_type, handle_incompatible, expected in test_cases:
        result = map_datatype_to_databricks(original_type, handle_incompatible)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"  {status} {original_type} (handle={handle_incompatible}) ‚Üí {result} (expected: {expected})")
        
        if result != expected:
            print(f"    ERROR: Expected {expected}, got {result}")
            all_passed = False
    
    print(f"  Data Type Mapping: {'PASSED' if all_passed else 'FAILED'}")
    print()
    return all_passed

def test_identity_column_support():
    """Test F-4: Identity column support"""
    print("üß™ Testing Identity Column Support...")
    
    test_cases = [
        # Test various identity indicators
        ({"identity": True}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"IDENTITY": True}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"generated_always": True}, "GENERATED ALWAYS AS IDENTITY"),
        ({"auto_increment": True}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"serial": True}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"description": "This is an identity column"}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"description": "Auto increment primary key"}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({"description": "Serial number field"}, "GENERATED BY DEFAULT AS IDENTITY"),
        ({}, ""),  # No identity indicators
        ({"some_other_field": True}, ""),  # Irrelevant field
    ]
    
    all_passed = True
    for metadata, expected in test_cases:
        result = get_identity_clause(metadata)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"  {status} {metadata} ‚Üí '{result}' (expected: '{expected}')")
        
        if result != expected:
            print(f"    ERROR: Expected '{expected}', got '{result}'")
            all_passed = False
    
    print(f"  Identity Column Support: {'PASSED' if all_passed else 'FAILED'}")
    print()
    return all_passed

def test_column_formatting():
    """Test F-7: Output formatting"""
    print("üß™ Testing Column Formatting...")
    
    # Test column alignment
    test_cases = [
        ("customer_id", "BIGINT", True, "Primary key", "GENERATED BY DEFAULT AS IDENTITY", 20, 15),
        ("name", "STRING", False, "Customer name", "", 20, 15),
        ("created_at", "TIMESTAMP", True, "", "", 20, 15),
    ]
    
    print("  Testing column alignment:")
    for col_name, data_type, not_null, comment, identity, max_name, max_type in test_cases:
        result = format_column_definition(col_name, data_type, not_null, comment, identity, max_name, max_type)
        print(f"    {result}")
    
    # Test that columns are properly aligned
    results = []
    for col_name, data_type, not_null, comment, identity, max_name, max_type in test_cases:
        result = format_column_definition(col_name, data_type, not_null, comment, identity, max_name, max_type)
        results.append(result)
    
    # Check if all column names start at the same position (after "  ")
    # and data types are aligned
    all_aligned = True
    for result in results:
        if not result.startswith("  "):
            all_aligned = False
            break
    
    print(f"  Column Formatting: {'PASSED' if all_aligned else 'FAILED'}")
    print()
    return all_aligned

def test_identifier_sanitization():
    """Test identifier sanitization"""
    print("üß™ Testing Identifier Sanitization...")
    
    test_cases = [
        ("Customer ID", "underscore", "Customer_ID"),
        ("Customer ID", "backtick", "`Customer ID`"),
        ("Order-Details", "underscore", "Order_Details"),
        ("Order-Details", "backtick", "`Order-Details`"),
        ("Normal_Name", "underscore", "Normal_Name"),
        ("Normal_Name", "backtick", "`Normal_Name`"),
        # Test dot sanitization (important for catalog/schema names)
        ("crm.sales", "underscore", "crm_sales"),
        ("env.catalog", "underscore", "env_catalog"),
        ("schema.with.dots", "underscore", "schema_with_dots"),
    ]
    
    all_passed = True
    for original, method, expected in test_cases:
        result = sanitize_identifier(original, method)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"  {status} '{original}' ({method}) ‚Üí '{result}' (expected: '{expected}')")
        
        if result != expected:
            print(f"    ERROR: Expected '{expected}', got '{result}'")
            all_passed = False
    
    print(f"  Identifier Sanitization: {'PASSED' if all_passed else 'FAILED'}")
    print()
    return all_passed

def main():
    """Run all tests"""
    print("üöÄ Running Databricks DDL Generator Core Function Tests\n")
    
    # Test all core functions
    results = []
    results.append(test_data_type_mapping())
    results.append(test_identity_column_support())
    results.append(test_column_formatting())
    results.append(test_identifier_sanitization())
    
    all_passed = all(results)
    
    print("=" * 60)
    print(f"üéØ Overall Test Result: {'‚úÖ ALL TESTS PASSED' if all_passed else '‚ùå SOME TESTS FAILED'}")
    print("=" * 60)
    
    print("\nüìã Summary of Tested Features:")
    print("  ‚Ä¢ F-1: Enhanced data type mapping engine (BIT‚ÜíBOOLEAN, etc.)")
    print("  ‚Ä¢ F-4: Identity column support (GENERATED BY DEFAULT AS IDENTITY)")
    print("  ‚Ä¢ F-7: Improved output formatting and alignment")
    print("  ‚Ä¢ Identifier sanitization for spaces and special characters")
    
    if all_passed:
        print("\nüéâ All core functions are working correctly!")
        print("The app should now handle:")
        print("  - BIT data types correctly (maps to BOOLEAN)")
        print("  - Identity columns with proper syntax")
        print("  - Properly formatted and aligned DDL output")
        print("  - Spaces in table/column names")
    else:
        print("\n‚ö†Ô∏è  Some tests failed. Please review the implementation.")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    exit(main()) 